{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import typing\n",
    "import numpy as np\n",
    "from types import SimpleNamespace as ns\n",
    "from utils import load_cuda, cuda_begin, cdiv\n",
    "import cuda_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, linewidth=140)\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcbf0528650>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.rand(32,64,128,128).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361 µs ± 183 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "res = torch.argmax(m, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374 µs ± 205 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "cuda_res = cuda_ext.argmax(m, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.int8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = torch.argmax(m, dim=0)\n",
    "cuda_res = cuda_ext.argmax(m, dim=0)\n",
    "print(res.dtype, cuda_res.dtype)\n",
    "torch.isclose(res.to(torch.int8),cuda_res).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty        87.82%       3.020ms        87.82%       3.020ms       3.020ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b       1.00 Mb       1.00 Mb             1  \n",
      "                                            aten::zeros         1.13%      39.000us        91.57%       3.149ms       3.149ms       0.000us         0.00%       3.000us       3.000us           0 b           0 b       1.00 Mb           0 b             1  \n",
      "                                            aten::zero_         0.47%      16.000us         2.62%      90.000us      90.000us       0.000us         0.00%       3.000us       3.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                            aten::fill_         0.81%      28.000us         2.15%      74.000us      74.000us       3.000us         1.14%       3.000us       3.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                       cudaLaunchKernel         9.33%     321.000us         9.33%     321.000us     160.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.000us         1.14%       3.000us       3.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                       cuda_ext::argmax         0.29%      10.000us         8.35%     287.000us     287.000us     260.000us        98.86%     260.000us     260.000us           0 b           0 b           0 b           0 b             1  \n",
      "void cuda_ext::(anonymous namespace)::argmax_kernel<...         0.00%       0.000us         0.00%       0.000us       0.000us     260.000us        98.86%     260.000us     260.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                  cudaDeviceSynchronize         0.15%       5.000us         0.15%       5.000us       1.667us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.439ms\n",
      "Self CUDA time total: 263.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-10-13 17:05:11 19771:19771 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2024-10-13 17:05:11 19771:19771 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-10-13 17:05:11 19771:19771 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,  # Track CPU activity\n",
    "        torch.profiler.ProfilerActivity.CUDA  # Track GPU activity (for memory and time)\n",
    "    ],\n",
    "    record_shapes=True,  # Records shapes of operator inputs\n",
    "    profile_memory=True, # Tracks memory usage\n",
    "    with_stack=True      # Captures stack traces (optional, useful for deep debugging)\n",
    ") as prof:\n",
    "    result = cuda_ext.argmax(m, dim=0)\n",
    "    # res = torch.argmax(m, dim=0)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "print(prof.key_averages().table(\n",
    "    sort_by=\"self_cuda_memory_usage\",  # Sort by GPU memory usage\n",
    "    row_limit=10                       # Limit rows (useful for large reports)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::argmax        91.41%       3.416ms        99.89%       3.733ms       3.733ms     272.000us       100.00%     272.000us     272.000us           0 b           0 b       8.00 Mb       8.00 Mb             1  \n",
      "                                       aten::as_strided         0.13%       5.000us         0.13%       5.000us       5.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                       cudaLaunchKernel         8.35%     312.000us         8.35%     312.000us     312.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     272.000us       100.00%     272.000us     272.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                  cudaDeviceSynchronize         0.11%       4.000us         0.11%       4.000us       2.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      -8.00 Mb      -8.00 Mb             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.737ms\n",
      "Self CUDA time total: 272.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-10-13 17:05:12 19771:19771 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2024-10-13 17:05:12 19771:19771 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-10-13 17:05:12 19771:19771 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,  # Track CPU activity\n",
    "        torch.profiler.ProfilerActivity.CUDA  # Track GPU activity (for memory and time)\n",
    "    ],\n",
    "    record_shapes=True,  # Records shapes of operator inputs\n",
    "    profile_memory=True, # Tracks memory usage\n",
    "    with_stack=True      # Captures stack traces (optional, useful for deep debugging)\n",
    ") as prof:\n",
    "    # result = cuda_ext.argmax(m, dim=0)\n",
    "    res = torch.argmax(m, dim=0)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "print(prof.key_averages().table(\n",
    "    sort_by=\"self_cuda_memory_usage\",  # Sort by GPU memory usage\n",
    "    row_limit=10                       # Limit rows (useful for large reports)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layernorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_length, embedding_dim = 64, 64\n",
    "embedding = torch.randn(sentence_length, embedding_dim).cuda()\n",
    "layer_norm = nn.LayerNorm(embedding_dim).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.6 µs ± 22.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "with torch.no_grad():\n",
    "    torch_result = layer_norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.3 µs ± 26.5 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "cuda_result = cuda_ext.layernorm_welford(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.1 µs ± 26.2 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "cuda_result = cuda_ext.layernorm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    torch_result = layer_norm(embedding)\n",
    "cuda_result_welford = cuda_ext.layernorm_welford(embedding)\n",
    "cuda_result = cuda_ext.layernorm_welford(embedding)\n",
    "print(torch.allclose(torch_result, cuda_result, rtol=1e-03))\n",
    "print(torch.allclose(cuda_result_welford, cuda_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty         1.60%      36.000us         1.60%      36.000us      12.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      17.00 Kb      17.00 Kb             3  \n",
      "                                       aten::layer_norm         0.44%      10.000us        99.82%       2.250ms       2.250ms       0.000us         0.00%       4.000us       4.000us           0 b           0 b      17.00 Kb           0 b             1  \n",
      "                                aten::native_layer_norm        95.43%       2.151ms        99.38%       2.240ms       2.240ms       4.000us       100.00%       4.000us       4.000us           0 b           0 b      17.00 Kb           0 b             1  \n",
      "                                       cudaLaunchKernel         2.17%      49.000us         2.17%      49.000us      49.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us       4.000us       100.00%       4.000us       4.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                             aten::view         0.18%       4.000us         0.18%       4.000us       2.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                  cudaDeviceSynchronize         0.18%       4.000us         0.18%       4.000us       4.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     -16.00 Kb     -16.00 Kb             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.254ms\n",
      "Self CUDA time total: 4.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-10-13 17:08:52 19861:19861 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2024-10-13 17:08:52 19861:19861 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-10-13 17:08:52 19861:19861 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,  # Track CPU activity\n",
    "        torch.profiler.ProfilerActivity.CUDA  # Track GPU activity (for memory and time)\n",
    "    ],\n",
    "    record_shapes=True,  # Records shapes of operator inputs\n",
    "    profile_memory=True, # Tracks memory usage\n",
    "    with_stack=True      # Captures stack traces (optional, useful for deep debugging)\n",
    ") as prof:\n",
    "    torch_result = layer_norm(embedding)\n",
    "\n",
    "print(prof.key_averages().table(\n",
    "    sort_by=\"self_cuda_memory_usage\",  # Sort by GPU memory usage\n",
    "    row_limit=10                       # Limit rows (useful for large reports)\n",
    "))\n",
    "del prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty        93.47%       2.174ms        93.47%       2.174ms       2.174ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b      16.00 Kb      16.00 Kb             1  \n",
      "                                            aten::zeros         1.46%      34.000us        98.62%       2.294ms       2.294ms       0.000us         0.00%       1.000us       1.000us           0 b           0 b      16.00 Kb           0 b             1  \n",
      "                                            aten::zero_         0.56%      13.000us         3.70%      86.000us      86.000us       0.000us         0.00%       1.000us       1.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                            aten::fill_         1.16%      27.000us         3.14%      73.000us      73.000us       1.000us        25.00%       1.000us       1.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                       cudaLaunchKernel         2.75%      64.000us         2.75%      64.000us      32.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.000us        25.00%       1.000us       1.000us           0 b           0 b           0 b           0 b             1  \n",
      "                            cuda_ext::layernorm_welford         0.43%      10.000us         1.29%      30.000us      30.000us       3.000us        75.00%       3.000us       3.000us           0 b           0 b           0 b           0 b             1  \n",
      "void cuda_ext::(anonymous namespace)::layernorm_welf...         0.00%       0.000us         0.00%       0.000us       0.000us       3.000us        75.00%       3.000us       3.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                  cudaDeviceSynchronize         0.17%       4.000us         0.17%       4.000us       2.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.326ms\n",
      "Self CUDA time total: 4.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-10-13 17:09:34 19914:19914 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2024-10-13 17:09:34 19914:19914 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-10-13 17:09:34 19914:19914 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,  # Track CPU activity\n",
    "        torch.profiler.ProfilerActivity.CUDA  # Track GPU activity (for memory and time)\n",
    "    ],\n",
    "    record_shapes=True,  # Records shapes of operator inputs\n",
    "    profile_memory=True, # Tracks memory usage\n",
    "    with_stack=True      # Captures stack traces (optional, useful for deep debugging)\n",
    ") as prof:\n",
    "    cuda_result = cuda_ext.layernorm_welford(embedding)\n",
    "print(prof.key_averages().table(\n",
    "    sort_by=\"self_cuda_memory_usage\",  # Sort by GPU memory usage\n",
    "    row_limit=10                       # Limit rows (useful for large reports)\n",
    "))\n",
    "del prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty        94.43%       2.271ms        94.43%       2.271ms       2.271ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b      16.00 Kb      16.00 Kb             1  \n",
      "                                            aten::zeros         1.00%      24.000us        98.67%       2.373ms       2.373ms       0.000us         0.00%       1.000us       1.000us           0 b           0 b      16.00 Kb           0 b             1  \n",
      "                                            aten::zero_         0.29%       7.000us         3.24%      78.000us      78.000us       0.000us         0.00%       1.000us       1.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                            aten::fill_         1.04%      25.000us         2.95%      71.000us      71.000us       1.000us        25.00%       1.000us       1.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                       cudaLaunchKernel         2.66%      64.000us         2.66%      64.000us      32.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.000us        25.00%       1.000us       1.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                    cuda_ext::layernorm         0.42%      10.000us         1.25%      30.000us      30.000us       3.000us        75.00%       3.000us       3.000us           0 b           0 b           0 b           0 b             1  \n",
      "void cuda_ext::(anonymous namespace)::layernorm_kern...         0.00%       0.000us         0.00%       0.000us       0.000us       3.000us        75.00%       3.000us       3.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                  cudaDeviceSynchronize         0.17%       4.000us         0.17%       4.000us       2.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     -16.00 Kb     -16.00 Kb             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.405ms\n",
      "Self CUDA time total: 4.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-10-13 17:09:37 19914:19914 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2024-10-13 17:09:37 19914:19914 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2024-10-13 17:09:37 19914:19914 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,  # Track CPU activity\n",
    "        torch.profiler.ProfilerActivity.CUDA  # Track GPU activity (for memory and time)\n",
    "    ],\n",
    "    record_shapes=True,  # Records shapes of operator inputs\n",
    "    profile_memory=True, # Tracks memory usage\n",
    "    with_stack=True      # Captures stack traces (optional, useful for deep debugging)\n",
    ") as prof:\n",
    "    cuda_result = cuda_ext.layernorm(embedding)\n",
    "print(prof.key_averages().table(\n",
    "    sort_by=\"self_cuda_memory_usage\",  # Sort by GPU memory usage\n",
    "    row_limit=10                       # Limit rows (useful for large reports)\n",
    "))\n",
    "del prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src = cuda_begin + r'''\n",
    "\n",
    "template <typename T>\n",
    "__device__ bool greater_function(T data1, T data2) {\n",
    "    return data1 > data2;\n",
    "}\n",
    "\n",
    "template <typename T>\n",
    "__device__ int max_index_function(T* data, int stride, int length) {\n",
    "    T max_value = data[0];\n",
    "    int max_index = 0;\n",
    "\n",
    "    int index = 0;\n",
    "    for (int i=1; i<length; ++i) {\n",
    "        index += stride;\n",
    "        if (greater_function<T>(data[index], max_value)) {\n",
    "            max_value = data[index];\n",
    "            max_index = i;\n",
    "        }\n",
    "    }\n",
    "    return max_index;\n",
    "}\n",
    "\n",
    "\n",
    "template <typename T>\n",
    "__global__ void argmax_kernel(void* data, char* index, int number, int stride, int length) {\n",
    "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    if (i < number) {\n",
    "        int row = i / stride;\n",
    "        int col = i % stride;\n",
    "        argmax_index[i] = max_index_function<T>((T*)data + row * length * stride + col, stride, length);\n",
    "    }\n",
    "}\n",
    "\n",
    "void argmax_cuda(torch::Tensor data, torch::Tensor index, int64_t number, int64_t stride, int64_t length) {\n",
    "    data = data.contiguous();\n",
    "    index = index.contiguous();\n",
    "    int gpu_id = index.device().index();\n",
    "    cudaSetDevice(gpu_id);\n",
    "\n",
    "    block_size = 32;\n",
    "    argmax_kernel<float><<<cdiv(1.0*number/block_size), block_size>>>((void*)data.data_ptr(), (char*)index.data_ptr(), number, stride, length);\n",
    "    cudaDeviceSynchronize();\n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig(fname, src):\n",
    "    res = re.findall(rf'^(.+\\s+{fname}\\s*\\([^\\)]*\\))\\s*\\{{', src, re.MULTILINE)\n",
    "    return res[0] + ';' if res else None\n",
    "\n",
    "\n",
    "fname = 'argmax_cuda'\n",
    "cpp_src = get_sig(fname, cuda_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void argmax_cuda(torch::Tensor data, torch::Tensor index, int64_t number, int64_t stride, int64_t length);\n"
     ]
    }
   ],
   "source": [
    "print(cpp_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error building extension 'argmax_cuda_v3': [1/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=argmax_cuda_v3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/TH -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /root/miniconda3/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -O3 -Xptxas -O3 -Xcompiler -O3 -std=c++17 -c /root/.cache/torch_extensions/py310_cu121/argmax_cuda/cuda.cu -o cuda.cuda.o \n\u001b[31mFAILED: \u001b[0mcuda.cuda.o \n/usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=argmax_cuda_v3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/TH -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /root/miniconda3/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -O3 -Xptxas -O3 -Xcompiler -O3 -std=c++17 -c /root/.cache/torch_extensions/py310_cu121/argmax_cuda/cuda.cu -o cuda.cuda.o \n/root/.cache/torch_extensions/py310_cu121/argmax_cuda/cuda.cu(52): error: identifier \"argmax_index\" is undefined\n          argmax_index[i] = max_index_function<T>((T*)data + row * length * stride + col, stride, length);\n          ^\n\n/root/.cache/torch_extensions/py310_cu121/argmax_cuda/cuda.cu(62): error: identifier \"block_size\" is undefined\n      block_size = 32;\n      ^\n\n/root/.cache/torch_extensions/py310_cu121/argmax_cuda/cuda.cu(63): error: too few arguments in function call\n      argmax_kernel<float><<<cdiv(1.0*number/block_size), block_size>>>((void*)data.data_ptr(), (char*)index.data_ptr(), number, stride, length);\n                                                       ^\n\n3 errors detected in the compilation of \"/root/.cache/torch_extensions/py310_cu121/argmax_cuda/cuda.cu\".\n[2/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=argmax_cuda_v3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/TH -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /root/miniconda3/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /root/.cache/torch_extensions/py310_cu121/argmax_cuda/main.cpp -o main.o \nninja: build stopped: subcommand failed.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2100\u001b[0m, in \u001b[0;36m_run_ninja_build\u001b[0;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[1;32m   2099\u001b[0m     stdout_fileno \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2100\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstdout_fileno\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTDOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2106\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2108\u001b[0m     \u001b[38;5;66;03m# Python 2 and 3 compatible way of getting the error object.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/subprocess.py:526\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    527\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ninja', '-v']' returned non-zero exit status 1.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mload_cuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpp_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marg_max\u001b[39m(\n\u001b[1;32m      3\u001b[0m         matrix: typing\u001b[38;5;241m.\u001b[39mUnion[torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mFloatTensor, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mHalfTensor], \n\u001b[1;32m      4\u001b[0m         dim: \u001b[38;5;28mint\u001b[39m, \n\u001b[1;32m      5\u001b[0m         keepdim: \u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mCharTensor:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m matrix\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m [torch\u001b[38;5;241m.\u001b[39mfloat32, torch\u001b[38;5;241m.\u001b[39mfloat16], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly support float32 and float16\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/autodl-tmp/code/torchops/utils.py:29\u001b[0m, in \u001b[0;36mload_cuda\u001b[0;34m(cuda_src, cpp_src, funcs, opt, verbose, name)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_cuda\u001b[39m(cuda_src, cpp_src, funcs, opt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimple wrapper for torch.utils.cpp_extension.load_inline\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: name \u001b[38;5;241m=\u001b[39m funcs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     31\u001b[0m     flags \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-O3 -Xptxas -O3 -Xcompiler -O3\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-O0 -Xptxas -O0 -Xcompiler -O0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1635\u001b[0m, in \u001b[0;36mload_inline\u001b[0;34m(name, cpp_sources, cuda_sources, functions, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, with_pytorch_error_handling, keep_intermediates, use_pch)\u001b[0m\n\u001b[1;32m   1631\u001b[0m     _maybe_write(cuda_source_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cuda_sources))\n\u001b[1;32m   1633\u001b[0m     sources\u001b[38;5;241m.\u001b[39mappend(cuda_source_path)\n\u001b[0;32m-> 1635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1710\u001b[0m, in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1706\u001b[0m                 hipified_sources\u001b[38;5;241m.\u001b[39madd(hipify_result[s_abs]\u001b[38;5;241m.\u001b[39mhipified_path \u001b[38;5;28;01mif\u001b[39;00m s_abs \u001b[38;5;129;01min\u001b[39;00m hipify_result \u001b[38;5;28;01melse\u001b[39;00m s_abs)\n\u001b[1;32m   1708\u001b[0m             sources \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(hipified_sources)\n\u001b[0;32m-> 1710\u001b[0m         \u001b[43m_write_ninja_file_and_build_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m            \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1716\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1717\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1719\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_standalone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1722\u001b[0m     baton\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1823\u001b[0m, in \u001b[0;36m_write_ninja_file_and_build_library\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_standalone)\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m   1822\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuilding extension module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m-> 1823\u001b[0m \u001b[43m_run_ninja_build\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1826\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError building extension \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2116\u001b[0m, in \u001b[0;36m_run_ninja_build\u001b[0;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[1;32m   2114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(error, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m error\u001b[38;5;241m.\u001b[39moutput:  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   2115\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;241m*\u001b[39mSUBPROCESS_DECODE_ARGS)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m-> 2116\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error building extension 'argmax_cuda_v3': [1/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=argmax_cuda_v3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/TH -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /root/miniconda3/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -O3 -Xptxas -O3 -Xcompiler -O3 -std=c++17 -c /root/.cache/torch_extensions/py310_cu121/argmax_cuda/cuda.cu -o cuda.cuda.o \n\u001b[31mFAILED: \u001b[0mcuda.cuda.o \n/usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=argmax_cuda_v3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/TH -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /root/miniconda3/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -O3 -Xptxas -O3 -Xcompiler -O3 -std=c++17 -c /root/.cache/torch_extensions/py310_cu121/argmax_cuda/cuda.cu -o cuda.cuda.o \n/root/.cache/torch_extensions/py310_cu121/argmax_cuda/cuda.cu(52): error: identifier \"argmax_index\" is undefined\n          argmax_index[i] = max_index_function<T>((T*)data + row * length * stride + col, stride, length);\n          ^\n\n/root/.cache/torch_extensions/py310_cu121/argmax_cuda/cuda.cu(62): error: identifier \"block_size\" is undefined\n      block_size = 32;\n      ^\n\n/root/.cache/torch_extensions/py310_cu121/argmax_cuda/cuda.cu(63): error: too few arguments in function call\n      argmax_kernel<float><<<cdiv(1.0*number/block_size), block_size>>>((void*)data.data_ptr(), (char*)index.data_ptr(), number, stride, length);\n                                                       ^\n\n3 errors detected in the compilation of \"/root/.cache/torch_extensions/py310_cu121/argmax_cuda/cuda.cu\".\n[2/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=argmax_cuda_v3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/TH -isystem /root/miniconda3/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /root/miniconda3/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /root/.cache/torch_extensions/py310_cu121/argmax_cuda/main.cpp -o main.o \nninja: build stopped: subcommand failed.\n"
     ]
    }
   ],
   "source": [
    "module = load_cuda(cuda_src, cpp_src, [fname], opt=True)\n",
    "def arg_max(\n",
    "        matrix: typing.Union[torch.cuda.FloatTensor, torch.cuda.HalfTensor], \n",
    "        dim: int, \n",
    "        keepdim: bool=False) -> torch.cuda.CharTensor:\n",
    "    \n",
    "    assert matrix.dtype in [torch.float32, torch.float16], \"only support float32 and float16\"\n",
    "    assert isinstance(matrix, torch.Tensor) and matrix.is_cuda, \"only support torch.Tensor, gpu\"\n",
    "    assert matrix.ndim > dim, f\"matrix.ndim({matrix.ndim}) should be larger than dim({dim})\"\n",
    "    assert dim >= 0, f\"dim({dim}) should be >= 0\"\n",
    "\n",
    "    shape = [i for i in matrix.shape]\n",
    "    assert shape[dim] <= 128, f\"shape[dim]({shape[dim]}) should be <= 128\"\n",
    "\n",
    "    number, stride, length = 1, 1, shape[dim]\n",
    "    \n",
    "    for i in range(dim+1, matrix.ndim):\n",
    "        stride *= shape[i]\n",
    "\n",
    "    number = stride\n",
    "\n",
    "    for i in range(dim):\n",
    "        number *= shape[i]\n",
    "\n",
    "    if keepdim:\n",
    "        shape[dim] = 1\n",
    "    else:\n",
    "        shape.pop(dim)\n",
    "\n",
    "    index_cuda = torch.zeros(shape, dtype = torch.int8, device=matrix.device)\n",
    "\n",
    "    # torch.ops.ext.argmax(matrix, index_cuda, number, stride, length)\n",
    "    module.argmax_cuda(matrix, index_cuda, number, stride, length)\n",
    "\n",
    "    return index_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/root/.cache/torch_extensions/py310_cu121/argmax_cuda/argmax_cuda_v1.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43marg_max\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[82], line 32\u001b[0m, in \u001b[0;36marg_max\u001b[0;34m(matrix, dim, keepdim)\u001b[0m\n\u001b[1;32m     29\u001b[0m index_cuda \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(shape, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mint8, device\u001b[38;5;241m=\u001b[39mmatrix\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# torch.ops.ext.argmax(matrix, index_cuda, number, stride, length)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mload_cuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpp_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m module\u001b[38;5;241m.\u001b[39margmax_cuda(matrix)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index_cuda\n",
      "File \u001b[0;32m~/autodl-tmp/code/torchops/utils.py:29\u001b[0m, in \u001b[0;36mload_cuda\u001b[0;34m(cuda_src, cpp_src, funcs, opt, verbose, name)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_cuda\u001b[39m(cuda_src, cpp_src, funcs, opt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimple wrapper for torch.utils.cpp_extension.load_inline\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: name \u001b[38;5;241m=\u001b[39m funcs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     31\u001b[0m     flags \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-O3 -Xptxas -O3 -Xcompiler -O3\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m opt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-O0 -Xptxas -O0 -Xcompiler -O0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1635\u001b[0m, in \u001b[0;36mload_inline\u001b[0;34m(name, cpp_sources, cuda_sources, functions, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, with_pytorch_error_handling, keep_intermediates, use_pch)\u001b[0m\n\u001b[1;32m   1631\u001b[0m     _maybe_write(cuda_source_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cuda_sources))\n\u001b[1;32m   1633\u001b[0m     sources\u001b[38;5;241m.\u001b[39mappend(cuda_source_path)\n\u001b[0;32m-> 1635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1736\u001b[0m, in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_standalone:\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_exec_path(name, build_directory)\n\u001b[0;32m-> 1736\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_import_module_from_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2136\u001b[0m, in \u001b[0;36m_import_module_from_library\u001b[0;34m(module_name, path, is_python_module)\u001b[0m\n\u001b[1;32m   2134\u001b[0m spec \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mspec_from_file_location(module_name, filepath)\n\u001b[1;32m   2135\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2136\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_from_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2137\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec\u001b[38;5;241m.\u001b[39mloader, importlib\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mLoader)\n\u001b[1;32m   2138\u001b[0m spec\u001b[38;5;241m.\u001b[39mloader\u001b[38;5;241m.\u001b[39mexec_module(module)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:571\u001b[0m, in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1176\u001b[0m, in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /root/.cache/torch_extensions/py310_cu121/argmax_cuda/argmax_cuda_v1.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "result = arg_max(m, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
